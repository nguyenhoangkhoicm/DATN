
from ai_function.access_schedule import schedule
from ai_function.speaklisten import speaker
from ai_function.point_lookup import point_lookup
from ai_function.sleep import function
from ai_function.determine_most_similar import determine_most_similar_phrase
from intentclassification.intent_classification import IntentClassifier

from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtCore import pyqtSlot
from PyQt5.QtGui import QMovie

from googleapiclient.discovery import build

import pyaudio
import json
import random
import sys
import os
import struct
import pvporcupine
import webbrowser
import playsound
import speech_recognition as sr


class AssistantThread(QtCore.QThread):

    answer_signal = QtCore.pyqtSignal(str)

    def __init__(self, name):
        super().__init__()
        self.name = name
        self.intentclassifier = IntentClassifier()

    def command(self, count=0):
        playsound.playsound("./sound/Ping.mp3", False)
        r = sr.Recognizer()
        with sr.Microphone() as source:
            audio = r.record(source, duration=6)
            try:
                text = r.recognize_google(audio, language='vi')
                print("üßë: " + text)
                if text.lower() == "hey siri":
                    count = 0
            except sr.UnknownValueError:

                text = "Xin l·ªói t√¥i kh√¥ng nghe th·∫•y b·∫°n n√≥i g√¨, b·∫°n c√≥ th·ªÉ n√≥i l·∫°i kh√¥ng."
                self.answer_signal.emit(text)
                speaker.speak(text)
                count += 1

                if count == 3:

                    text = "T√¥i s·∫Ω t·∫°m d·ª´ng cho ƒë·∫øn khi b·∫°n g·ªçi t√™n Hey siri"

                    speaker.speak(text)

                    while True:
                        try:
                            speaker.siri()
                            break
                        except sr.UnknownValueError:
                            pass
                    count = 0

                text = speaker.command(count)

        return text.lower()

    def run(self):
        with open('samples/hello_assistant.json', encoding='utf-8') as f:
            data = json.load(f)
            self.questions = data.get('', [])
        question = random.choice(self.questions)
        self.answer_signal.emit(question)
        speaker.speak(question)

        # Kh·ªüi t·∫°o c√°c bi·∫øn.
        self.porcupine = None
        pa = None
        audio_stream = None

        # Ph√°t hi·ªán t·ª´ ƒë√°nh th·ª©c.
        access_key = "08RPO8infyitaLPnJPEfKTK3+l3Cc73mZB2JDtEIVz71RYJ9TOYk/Q=="
        self.porcupine = pvporcupine.create(
            access_key=access_key, keywords=[self.name])

        # T·∫°o m·ªôt ƒë·ªëi t∆∞·ª£ng PyAudio.
        pa = pyaudio.PyAudio()

        # M·ªü lu·ªìng t·ªõi microphone.
        audio_stream = pa.open(rate=self.porcupine.sample_rate, channels=1, format=pyaudio.paInt16, input=True,
                               frames_per_buffer=self.porcupine.frame_length)

        while True:
            try:
                # ƒê·ªçc lu·ªìng √¢m thanh v√† chuy·ªÉn ƒë·ªïi n√≥ sang ƒë·ªãnh d·∫°ng m√† porcupine c√≥ th·ªÉ hi·ªÉu.
                pcm = audio_stream.read(self.porcupine.frame_length)
                pcm = struct.unpack_from(
                    "h" * self.porcupine.frame_length, pcm)
            except:
                # M·ªü lu·ªìng t·ªõi microphone.
                audio_stream = pa.open(rate=self.porcupine.sample_rate, channels=1, format=pyaudio.paInt16, input=True,
                                       frames_per_buffer=self.porcupine.frame_length)

            # X·ª≠ l√Ω lu·ªìng √¢m thanh v√† ki·ªÉm tra xem t·ª´ kh√≥a c√≥ ƒë∆∞·ª£c ph√°t hi·ªán hay kh√¥ng.
            keyword_index = self.porcupine.process(pcm)

            # Tr·ª£ l√Ω nghe ƒë∆∞·ª£c t·ª´ ƒë√°nh th·ª©c v√† sau ƒë√≥ l·∫Øng nghe ƒë·∫ßu v√†o c·ªßa ng∆∞·ªùi d√πng.
            if keyword_index >= 0:
                if audio_stream is not None:
                    with open('samples/answer_assistant.json', encoding='utf-8') as f:
                        data = json.load(f)
                        questions = data.get('', [])
                    question = random.choice(questions)
                    self.answer_signal.emit(question)
                    speaker.speak(question)
                    audio_stream.close()
                said = self.command()

                self.reply(said)

    @pyqtSlot(str)
    def search_on_web(self, query):
        try:
            # API key Google Developer Console
            api_key = "AIzaSyBRx6P6zJN8o6uIxje_AUzFT_OsXJRj-dU"
            # ID c·ªßa search engine
            search_engine_id = "b3474988609f744f1"

            service = build("customsearch", "v1", developerKey=api_key)
            response = service.cse().list(q=query, cx=search_engine_id, num=1).execute()
            items = response["items"]
            if items:
                return items[0]["link"]
        except Exception as e:
            print(f"C√≥ l·ªói x·∫£y ra khi t√¨m ki·∫øm tr√™n m·∫°ng: {str(e)}")

    def replys(self, text, intent):
        with open(f'./samples/{intent}.json', encoding='utf-8') as samplesfile:
            samples = json.load(samplesfile)
        most_similar = determine_most_similar_phrase(
            text=text, intent_dict=samples)

        if type(samples[most_similar]) == str:
            response = samples[most_similar]
            self.answer_signal.emit(response)
            speaker.speak(response)
        elif type(samples[most_similar]) == list:
            response = random.choice(samples[most_similar])
            self.answer_signal.emit(response)
            speaker.speak(response)

    def reply(self, text):
        
        intent = self.intentclassifier.predict(text)

        if intent == 'leaving':
            with open('samples/leaving.json', encoding='utf-8') as f:
                data = json.load(f)
                questions = data.get('', [])
            question = random.choice(questions)
            self.answer_signal.emit(question)
            speaker.speak(question)
            QtWidgets.QApplication.quit()
            sys.exit()

        replies = {
            'greeting': self.replys,
            'tuition': self.replys,
            'department': self.replys,
            'point': self.replys,
            'scholarship': self.replys,
            'pointlookup': point_lookup.main,
            'schedule': schedule.main,
            'sleep': function.main
        }
        if intent in replies:
            reply_func = replies[intent]

            if intent == "sleep":
                self.answer_signal.emit(
                    "V√¢ng, m√¨nh ng·ªß ƒë√¢y n·∫øu b·∫°n c·∫ßn m√¨nh h√£y g·ªçi t√™n Hey siri")
            elif intent == "pointlookup":
                with open('samples/rp_pl.json', encoding='utf-8') as f:
                    data = json.load(f)
                    self.questions = data.get('', [])
                question = random.choice(self.questions)
                self.answer_signal.emit(question)
                speaker.speak(question)
            elif intent == "schedule":
                with open('samples/access_schedule.json', encoding='utf-8') as f:
                    data = json.load(f)
                    questions = data.get('', [])
                question = random.choice(questions)
                self.answer_signal.emit(question)
                speaker.speak(question)

            # Ki·ªÉm tra xem ch·ª©c nƒÉng c√≥ th·ªÉ g·ªçi ƒë∆∞·ª£c kh√¥ng.
            if callable(reply_func):
                reply_func(text, intent)

                with open('samples/ask_again.json', encoding='utf-8') as f:
                    data = json.load(f)
                    questions = data.get('', [])
                question = random.choice(questions)
                self.answer_signal.emit(question)
                speaker.speak(question)
                said = self.command()

                self.reply(said)

        else:
            with open('samples/no_sp.json', encoding='utf-8') as f:
                data = json.load(f)
                questions = data.get('', [])
            question = random.choice(questions)
            self.answer_signal.emit(question)
            speaker.speak(question)

            # T√¨m ki·∫øm c√¢u tr·∫£ l·ªùi cho ng∆∞·ªùi d√πng tr√™n m·∫°ng v√† tr·∫£ v·ªÅ k·∫øt qu·∫£
            result = self.search_on_web(text)
            if result:
                with open('samples/info_search.json', encoding='utf-8') as f:
                    data = json.load(f)
                    questions = data.get('', [])
                question = random.choice(questions)
                self.answer_signal.emit(question)
                speaker.speak(question)
                print(result)
                webbrowser.open(result)
                with open('samples/ask_again.json', encoding='utf-8') as f:
                    data = json.load(f)
                    questions = data.get('', [])
                question = random.choice(questions)
                self.answer_signal.emit(question)
                speaker.speak(question)
                said = self.command()

                self.reply(said)
            else:
                question = "Xin l·ªói, minh kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ tr√™n m·∫°ng."
                self.answer_signal.emit(question)
                speaker.speak(question)


class Ui_MainWindow(object):
    def setupUi(self, MainWindow):
        MainWindow.setObjectName("MainWindow")
        MainWindow.resize(600, 800)

        MainWindow.setWindowFlags(QtCore.Qt.FramelessWindowHint)
        MainWindow.setAttribute(QtCore.Qt.WA_TranslucentBackground)

        icon = QtGui.QIcon("image/assistant_icon.ico")
        MainWindow.setWindowIcon(icon)

        self.timer = QtCore.QTimer()
        self.timer.timeout.connect(self.updateGif)
        self.timer.start(1000)

       # Center main window on screen
        desktop = QtWidgets.QApplication.desktop()
        screen_rect = desktop.screenGeometry()
        x = int((screen_rect.width() - MainWindow.width()) / 2)
        y = int((screen_rect.height() - MainWindow.height()) / 2)
        MainWindow.move(x, y)

        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName("centralwidget")

        # create label
        self.label = QtWidgets.QLabel(self.centralwidget)
        # Gi·∫£m k√≠ch th∆∞·ªõc c·ªßa label
        self.label.setMinimumSize(QtCore.QSize(400, 400))
        # Gi·∫£m k√≠ch th∆∞·ªõc c·ªßa label
        self.label.setMaximumSize(QtCore.QSize(400, 400))
        self.label.setObjectName("label")

        # create text edit
        self.answer_text = QtWidgets.QTextEdit(self.centralwidget)
        self.answer_text.setReadOnly(True)

        self.answer_text.setStyleSheet("""
            QTextEdit {
                background-color: rgba(255, 255, 255, 200);
                border: 1px solid rgba(0, 0, 0, 0.2);
                border-radius: 20px;
                padding: 10px;
            }
        """)
        self.answer_text.setFixedHeight(150)
        self.answer_text.setFixedWidth(300)
        self.answer_text.setSizePolicy(
            QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Expanding)
        self.answer_text.setVerticalScrollBarPolicy(
            QtCore.Qt.ScrollBarAlwaysOff)

        # create grid layout
        layout = QtWidgets.QGridLayout(self.centralwidget)
        layout.addWidget(self.label, 0, 0, alignment=QtCore.Qt.AlignCenter)
        # Khung QTextEdit n·∫±m b√™n ph·∫£i c·ªßa label
        layout.addWidget(self.answer_text, 0, 1)

        MainWindow.setCentralWidget(self.centralwidget)

    def updateGif(self):
        if os.path.exists('voice.mp3'):
            self.movie = QMovie("image/rob.gif")
            self.label.setMovie(self.movie)
            self.movie.start()
            animation = QtCore.QPropertyAnimation(self.label, b'geometry')
            animation.setDuration(1000)
            animation.setStartValue(self.label.geometry())
            animation.setEndValue(self.label.geometry().translated(100, 100))
            animation.start()
            self.answer_text.show()
        else:
            self.label.clear()
            self.answer_text.hide()

    def paintEvent(self, event):
        painter = QtGui.QPainter(self.viewport())
        painter.setRenderHint(QtGui.QPainter.Antialiasing)
        painter.setPen(QtCore.Qt.NoPen)
        painter.setBrush(self.palette().base())
        painter.drawRoundedRect(self.rect(), 20, 20)

        super().paintEvent(event)


class MainWindow(QtWidgets.QMainWindow):

    def __init__(self):
        super().__init__()

        # Giao di·ªán
        self.ui = Ui_MainWindow()
        self.ui.setupUi(self)

        # Kh·ªüi t·∫°o tr·ª£ l√Ω v√† ƒëa lu·ªìng tr·ª£ l√Ω
        self.assistant = AssistantThread("hey siri")
        self.assistant.answer_signal.connect(self.add_answer_item)
        self.assistant.start()

    def add_answer_item(self, answer):
        # Thi·∫øt l·∫≠p k√≠ch th∆∞·ªõc font ch·ªØ l√† 13
        self.ui.answer_text.setFontPointSize(13)
        # X√≥a n·ªôi dung hi·ªán t·∫°i c·ªßa QTextEdit
        self.ui.answer_text.clear()
        # Th√™m c√¢u tr·∫£ l·ªùi m·ªõi v√†o QTextEdit
        self.ui.answer_text.append(answer)

        # Di chuy·ªÉn con tr·ªè ƒë·∫øn cu·ªëi vƒÉn b·∫£n
        self.ui.answer_text.moveCursor(QtGui.QTextCursor.End)


if __name__ == '__main__':
    app = QtWidgets.QApplication(sys.argv)
    window = MainWindow()
    window.show()
    sys.exit(app.exec_())
